#Import necessary dependencies and settings
import pandas as pd
import numpy as np
import logging
import re
import pickle

from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, f1_score
from sklearn.linear_model import  LogisticRegression
from xgboost import XGBClassifier
from sklearn import svm
from cleaning import process_text

logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)

"""
User defined functions to perform data preprocessing, feature engineering,
training the model  
"""

# Extracting Features for all models
def extract_features(field,training_data,testing_data,type):
    """
    Extract features using different methods
    Args: 
        field (string): statement column    
        training_data (pandas.core.frame.DataFrame): training data
        testing_data (pandas.core.frame.DataFrame): test data
        type (string): feature type
    Returns:
        train & test features and feature transformer
    """
    logging.info("Extracting features and creating vocabulary...")
    
    if "binary" in type:
        
        # BINARY FEATURE REPRESENTATION
        cv= CountVectorizer(binary=True, max_df=0.95, analyzer=process_text)
        cv.fit_transform(training_data.values)
        
        train_feature_set=cv.transform(training_data.values)
        test_feature_set=cv.transform(testing_data.values)
        
        return train_feature_set,test_feature_set,cv
  
    elif "counts" in type:
        
        # COUNT BASED FEATURE REPRESENTATION
        cv= CountVectorizer(binary=False, max_df=0.95, analyzer=process_text)
        cv.fit_transform(training_data.values)
        train_feature_set=cv.transform(training_data.values)
        test_feature_set=cv.transform(testing_data.values)
        
        return train_feature_set,test_feature_set,cv
    else:    
        # TF-IDF BASED FEATURE REPRESENTATION
        tfidf_vectorizer=TfidfVectorizer(use_idf=True, max_df=0.95, analyzer=process_text)
        tfidf_vectorizer.fit_transform(training_data.values)
        
        train_feature_set=tfidf_vectorizer.transform(training_data.values)
        test_feature_set=tfidf_vectorizer.transform(testing_data.values)
        
        return train_feature_set,test_feature_set,tfidf_vectorizer


# Training model for all methods
def train_model(classifier, train_val, field,feature_rep,name):
    """
    Training the classifier for the provided features.
    Args: 
        classifier (sklearn.linear_model): statement column  
        train_val (pandas.core.frame.DataFrame): training data
        field (string): test data
        feature_rep (string): feature type
    Returns:
        model, feature transformer and f1-score
    """
    logging.info("Starting model training...")   
    # GET A TRAIN TEST SPLIT (set seed for consistent results)
    training_data, testing_data = train_test_split(train_val,random_state = 2000,)
    # features
    X_train=training_data['statement']
    X_test=testing_data['statement']
    # GET LABELS
    Y_train=training_data['label'].values
    Y_test=testing_data['label'].values
    # GET FEATURES
    train_features,test_features,feature_transformer=extract_features(field,X_train,X_test,type=feature_rep)
    logging.info("Training a Classification Model...")
    model=classifier.fit(train_features,Y_train)
    # GET PREDICTIONS
    predictions = model.predict(test_features)
    # GET EVALUATION NUMBERS ON TEST SET
    logging.info("Starting evaluation...")
    score = f1_score(Y_test,predictions)
    print("The F1 score of method ",name,"with TF-IDF BASED FEATURE REPRESENTATION is:",score)
    print(classification_report(Y_test,predictions))
    print("Confusion Matrix of",name,"with TF-IDF BASED FEATURE REPRESENTATION is:")
    print(confusion_matrix(Y_test,predictions))
    logging.info("Done training and evaluation.")
    
    return model,feature_transformer,score

if __name__ == "__main__":
    """
    Training the best model
    """
    # load the processed data
    train_news = pd.read_csv("C:\\AOA_proj\\Detecting-Fake-News-On-Social-Media-main\\data\\processed\\train.csv").drop('len', axis=1)
    val_news = pd.read_csv("C:\\AOA_proj\\Detecting-Fake-News-On-Social-Media-main\\data\\processed\\val.csv")

    # define the path for model and feature transformer
    model_path="C:\\AOA_proj\\Detecting-Fake-News-On-Social-Media-main\\models\\final_model.pkl"
    transformer_path="C:\\AOA_proj\\Detecting-Fake-News-On-Social-Media-main\\models\\transformer.pkl"

    #Merging the training and validation data together to train the model
    labelEncoder = LabelEncoder()
    frames = [train_news, val_news]
    train_val = pd.concat(frames)
    train_val['label'].value_counts()
    train_val['label'] = labelEncoder.fit_transform(train_val['label'])

    # Logistic Regression training model
    field='statement'
    LogR_clf = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)
    lr_model,transform,score = train_model(LogR_clf,train_val,field="statement",feature_rep="",name='LOGICAL REGRESSION')
    
    # XGBoost training model
    field='statement'
    XGBoost_clf = XGBClassifier(max_depth=15, learning_rate=0.3, n_estimators=150)
    XGBoost_model,transform,score = train_model(XGBoost_clf,train_val,field="statement",feature_rep="",name='XGBoost')
	
    #SVM training model
    field='statement'
    svm_clf = svm.SVC(kernel='linear')
    svm_model,transform,score = train_model(svm_clf,train_val,field="statement",feature_rep="",name='SVM')
